{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用一个神经网路解决 FizzBuzz 问题\n",
    "\n",
    "输入一个数字：\n",
    " - 可以被 15 整除就回传 FizzBuzz；\n",
    " - 可以被 3 整除就回传 Fizz；\n",
    " - 被 5 整除就回传 Buzz；\n",
    " - 都不能整除就回传原本的数字"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 用程式实做的话会长这样"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FizzBuzz\n",
      "Fizz\n",
      "Buzz\n"
     ]
    }
   ],
   "source": [
    "def fizz_buzz(num):\n",
    "    if num % 15 == 0:\n",
    "        return 'FizzBuzz'\n",
    "    elif num % 3 == 0:\n",
    "        return 'Fizz'\n",
    "    elif num % 5 == 0:\n",
    "        return 'Buzz'\n",
    "    else:\n",
    "        return str(num)\n",
    "    \n",
    "print(fizz_buzz(45))\n",
    "print(fizz_buzz(48))\n",
    "print(fizz_buzz(50))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 其实就是一个简单的分类问题"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fizz_buzz(num):\n",
    "    if num % 15 == 0:\n",
    "        return 0 # 'FizzBuzz'\n",
    "    elif num % 3 == 0:\n",
    "        return 1 # 'Fizz'\n",
    "    elif num % 5 == 0:\n",
    "        return 2 # 'Buzz'\n",
    "    else:\n",
    "        return 3 # ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 来看看深度学习怎么解决这皮毛问题"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "BATCH = 32\n",
    "DIGITS = 10\n",
    "EPOCH = 100\n",
    "DATASET_SIZE = 3000\n",
    "CLASSES = ['FizzBuzz', 'Fizz', 'Buzz', '']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 深度學習很難嗎？其實網路結構就這幾行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FizzBuzz(nn.Module):\n",
    "    def __init__(self, in_channel, out_channel):\n",
    "        super(FizzBuzz, self).__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(in_channel, 1024), ## 全连接层\n",
    "            nn.Dropout(0.5),             ## Dropout 避免 overfitting\n",
    "            nn.ReLU(),                   ## Activation 函式\n",
    "            nn.Linear(1024, 1024),       ## 全连接层\n",
    "            nn.Dropout(0.5),             ## Dropout 避免 overfitting\n",
    "            nn.ReLU(),                   ## Activation 函式\n",
    "            nn.Linear(1024, out_channel) ## 全连接层，以此例来说 out_channel 应该为 4\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layers(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 可参考 lost 函式清单\n",
    " - https://pytorch.org/docs/stable/nn.functional.html#loss-functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(model, optimizer, training_data):\n",
    "    model.train()\n",
    "\n",
    "    for data, label in training_data:\n",
    "        data = Variable(torch.FloatTensor(data))\n",
    "        label = Variable(torch.LongTensor(label))\n",
    "\n",
    "        out = model(data)\n",
    "        optimizer.zero_grad()\n",
    "        ## 常用分类问题的 loss 函式\n",
    "        classification_loss = F.cross_entropy(out, label) \n",
    "        classification_loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FizzBuzz(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=10, out_features=1024, bias=True)\n",
      "    (1): Dropout(p=0.5, inplace=False)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "    (4): Dropout(p=0.5, inplace=False)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=1024, out_features=4, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "m = FizzBuzz(DIGITS, 4)\n",
    "print(m) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 检查一下准确率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testing(model, data):\n",
    "    model.eval()\n",
    "    loss = []\n",
    "    correct = 0\n",
    "\n",
    "    for x, y in data:\n",
    "        x = Variable(torch.FloatTensor(x))\n",
    "        y = Variable(torch.LongTensor(y))\n",
    "\n",
    "        out = model(x)\n",
    "        loss += [F.cross_entropy(out, y).data.item()]\n",
    "        pred = out.data.max(1, keepdim=True)[1]\n",
    "        correct += pred.eq(y.data.view_as(pred)).sum()\n",
    "\n",
    "    avg_loss = sum(loss) / len(loss)\n",
    "\n",
    "    return {\n",
    "        'accuracy': 100.0 * correct/(len(loss)*BATCH),\n",
    "        'avg_loss': avg_loss\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 输入格式转换成二进制"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "def encoder(num):\n",
    "    return list(map(lambda x: int(x), ('{:0' + str(DIGITS) + 'b}').format(num))) \n",
    "\n",
    "print(encoder(2088))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 制造一大堆训练资料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_data(num_of_data, batch_size):\n",
    "    xs = []\n",
    "    ys = []\n",
    "    for _ in range(num_of_data):\n",
    "        x = random.randint(0, 2**DIGITS-1)\n",
    "        ## 输入资料\n",
    "        xs += [encoder(x)]\n",
    "        ## 预测目标\n",
    "        ys += [fizz_buzz(x)]\n",
    "\n",
    "    data = []\n",
    "    for b in range(num_of_data//batch_size):\n",
    "        xxs = xs[b*batch_size:(b+1)*batch_size]\n",
    "        yys = ys[b*batch_size:(b+1)*batch_size]\n",
    "        data += [(xxs, yys)]\n",
    "        \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = make_data(DATASET_SIZE, BATCH)\n",
    "testing_data = make_data(100, BATCH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== 开始训练 ====\n",
      "Epoch 100/100, Loss: 0.01230, Accuracy: 100.00%\r"
     ]
    }
   ],
   "source": [
    "optimizer = optim.SGD(m.parameters(), lr=0.02, momentum=0.9)\n",
    "\n",
    "print('==== 开始训练 ====')\n",
    "for epoch in range(1, EPOCH + 1):\n",
    "    training(m, optimizer, training_data)\n",
    "    res = testing(m, testing_data)\n",
    "    print('Epoch {}/{}, Loss: {:.5f}, Accuracy: {:.2f}%'.format(\n",
    "            epoch,\n",
    "            EPOCH,\n",
    "            res['avg_loss'],\n",
    "            res['accuracy'],\n",
    "        ), end='\\r')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 即时测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interactive_test(model):\n",
    "    while True:\n",
    "        num = input()\n",
    "        if num == 'q':\n",
    "            print('Bye~')\n",
    "            return\n",
    "        if int(num) >= 2**DIGITS:\n",
    "            print('请输入一个小于 {} 的数字'.format(2**DIGITS))\n",
    "            continue\n",
    "\n",
    "        ans = fizz_buzz(int(num))\n",
    "        x = Variable(torch.FloatTensor([encoder(int(num))]))\n",
    "\n",
    "        predict = model(x).data.max(1, keepdim=True)[1]\n",
    "        print('预测为: {}, 答案为: {}'.format(CLASSES[predict[0][0]], CLASSES[ans]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[提示] 请输入一个小于 1024 的数字. (或输入 \"q\" 离开)\n",
      "258\n",
      "预测为: Fizz, 答案为: Fizz\n",
      "333\n",
      "预测为: Fizz, 答案为: Fizz\n",
      "150\n",
      "预测为: FizzBuzz, 答案为: FizzBuzz\n",
      "50\n",
      "预测为: Buzz, 答案为: Buzz\n",
      "q\n",
      "Bye~\n"
     ]
    }
   ],
   "source": [
    "print('[提示] 请输入一个小于 {} 的数字. (或输入 \"q\" 离开)'.format(2**DIGITS))\n",
    "interactive_test(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
